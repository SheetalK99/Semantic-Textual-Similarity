{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\kadss\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\kadss\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kadss\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet_ic to\n",
      "[nltk_data]     C:\\Users\\kadss\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\kadss\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.corpus import wordnet as wn\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from collections import defaultdict\n",
    "import pprint\n",
    "import argparse\n",
    "import difflib\n",
    "from googletrans import Translator\n",
    "import numpy as np\n",
    "import pickle\n",
    "translator = Translator()\n",
    "import time\n",
    "from nltk.corpus import wordnet_ic\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from nltk.corpus import wordnet as wn\n",
    "brown_ic = wordnet_ic.ic('ic-brown.dat')\n",
    "nltk.download('wordnet_ic')\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.corpus import wordnet as wn\n",
    "import gensim\n",
    "import os\n",
    "import collections\n",
    "import smart_open\n",
    "import re\n",
    "import random\n",
    "from collections import Counter\n",
    "import spotlight\n",
    "nltk.download('wordnet')\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "pd.set_option('display.max_columns', None)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = pd.read_csv('data/train-set.txt', sep=\"\\t\",error_bad_lines=False)\n",
    "train = train[np.isfinite(train['Gold Tag'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Sentence1</th>\n",
       "      <th>Sentence2</th>\n",
       "      <th>Gold Tag</th>\n",
       "      <th>tokenized_sent1</th>\n",
       "      <th>tokenized_sent2</th>\n",
       "      <th>lemmatized_sent1</th>\n",
       "      <th>lemmatized_sent2</th>\n",
       "      <th>POS_Tags1</th>\n",
       "      <th>POS_Tags2</th>\n",
       "      <th>Root1</th>\n",
       "      <th>Root2</th>\n",
       "      <th>flagCheckRoot</th>\n",
       "      <th>baseline_sim</th>\n",
       "      <th>word_align_sim</th>\n",
       "      <th>info_con_sim</th>\n",
       "      <th>tag_overlap</th>\n",
       "      <th>verb_diff</th>\n",
       "      <th>noun_diff</th>\n",
       "      <th>adj_diff</th>\n",
       "      <th>adv_diff</th>\n",
       "      <th>mmr</th>\n",
       "      <th>res_sim</th>\n",
       "      <th>no_ques_diff</th>\n",
       "      <th>no_excl_diff</th>\n",
       "      <th>annotations_s1</th>\n",
       "      <th>annotations_s2</th>\n",
       "      <th>num_same_URI</th>\n",
       "      <th>overlap_types</th>\n",
       "      <th>common_entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s_1</td>\n",
       "      <td>But other sources close to the sale said Viven...</td>\n",
       "      <td>But other sources close to the sale said Viven...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[But, other, sources, close, to, the, sale, sa...</td>\n",
       "      <td>[But, other, sources, close, to, the, sale, sa...</td>\n",
       "      <td>[But, other, source, close, to, the, sale, sai...</td>\n",
       "      <td>[But, other, source, close, to, the, sale, sai...</td>\n",
       "      <td>[(But, CC), (other, JJ), (source, NN), (close,...</td>\n",
       "      <td>[(But, CC), (other, JJ), (source, NN), (close,...</td>\n",
       "      <td>said</td>\n",
       "      <td>said</td>\n",
       "      <td>True</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>0.740427</td>\n",
       "      <td>4.027374e+00</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>[0.8269078095811264, 0.7994004396802319, 0.499...</td>\n",
       "      <td>2.549887</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'URI': ['http://dbpedia.org/resource/Vivendi'...</td>\n",
       "      <td>{'URI': ['http://dbpedia.org/resource/Vivendi'...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s_2</td>\n",
       "      <td>Micron has declared its first quarterly profit...</td>\n",
       "      <td>Micron's numbers also marked the first quarter...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[Micron, has, declared, its, first, quarterly,...</td>\n",
       "      <td>[Micron, 's, numbers, also, marked, the, first...</td>\n",
       "      <td>[Micron, ha, declared, it, first, quarterly, p...</td>\n",
       "      <td>[Micron, 's, number, also, marked, the, first,...</td>\n",
       "      <td>[(Micron, NNP), (ha, NN), (declared, VBD), (it...</td>\n",
       "      <td>[(Micron, NNP), ('s, POS), (number, NN), (also...</td>\n",
       "      <td>declared</td>\n",
       "      <td>marked</td>\n",
       "      <td>False</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.790476</td>\n",
       "      <td>5.430591e+00</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[0.6470795835539085, 1.0, 0.000999000999000999...</td>\n",
       "      <td>2.770720</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'URI': [], 'types': []}</td>\n",
       "      <td>{'URI': ['http://dbpedia.org/resource/Micron_T...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s_3</td>\n",
       "      <td>The fines are part of failed Republican effort...</td>\n",
       "      <td>Perry said he backs the Senate's efforts, incl...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[The, fines, are, part, of, failed, Republican...</td>\n",
       "      <td>[Perry, said, he, backs, the, Senate, 's, effo...</td>\n",
       "      <td>[The, fine, are, part, of, failed, Republican,...</td>\n",
       "      <td>[Perry, said, he, back, the, Senate, 's, effor...</td>\n",
       "      <td>[(The, DT), (fine, NN), (are, VBP), (part, NN)...</td>\n",
       "      <td>[(Perry, NNP), (said, VBD), (he, PRP), (back, ...</td>\n",
       "      <td>are</td>\n",
       "      <td>said</td>\n",
       "      <td>False</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.652066</td>\n",
       "      <td>5.643231e+00</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.8500074996250188, 1000.9999999999999, 0, 1....</td>\n",
       "      <td>2.531463</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'URI': ['http://dbpedia.org/resource/Republic...</td>\n",
       "      <td>{'URI': ['http://dbpedia.org/resource/Perry', ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s_4</td>\n",
       "      <td>The American Anglican Council, which represent...</td>\n",
       "      <td>The American Anglican Council, which represent...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[The, American, Anglican, Council, ,, which, r...</td>\n",
       "      <td>[The, American, Anglican, Council, ,, which, r...</td>\n",
       "      <td>[The, American, Anglican, Council, ,, which, r...</td>\n",
       "      <td>[The, American, Anglican, Council, ,, which, r...</td>\n",
       "      <td>[(The, DT), (American, JJ), (Anglican, NNP), (...</td>\n",
       "      <td>[(The, DT), (American, JJ), (Anglican, NNP), (...</td>\n",
       "      <td>said</td>\n",
       "      <td>said</td>\n",
       "      <td>True</td>\n",
       "      <td>4.722222</td>\n",
       "      <td>0.930556</td>\n",
       "      <td>7.816363e+00</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.7000099996666778, 0.7500624843789052, 0, 0....</td>\n",
       "      <td>2.560187</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'URI': [], 'types': []}</td>\n",
       "      <td>{'URI': ['http://dbpedia.org/resource/American...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s_5</td>\n",
       "      <td>The tech-loaded Nasdaq composite rose 20.96 po...</td>\n",
       "      <td>The technology-laced Nasdaq Composite Index &lt;....</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[The, tech-loaded, Nasdaq, composite, rose, 20...</td>\n",
       "      <td>[The, technology-laced, Nasdaq, Composite, Ind...</td>\n",
       "      <td>[The, tech-loaded, Nasdaq, composite, rose, 20...</td>\n",
       "      <td>[The, technology-laced, Nasdaq, Composite, Ind...</td>\n",
       "      <td>[(The, DT), (tech-loaded, JJ), (Nasdaq, NNP), ...</td>\n",
       "      <td>[(The, DT), (technology-laced, JJ), (Nasdaq, N...</td>\n",
       "      <td>rose</td>\n",
       "      <td>climbed</td>\n",
       "      <td>False</td>\n",
       "      <td>1.176471</td>\n",
       "      <td>0.562302</td>\n",
       "      <td>1.428571e+299</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.9990009990009991, 0.4999997502498749, 1000....</td>\n",
       "      <td>2.709486</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'URI': ['http://dbpedia.org/resource/Nasdaq_C...</td>\n",
       "      <td>{'URI': ['http://dbpedia.org/resource/Nasdaq_C...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                          Sentence1  \\\n",
       "0  s_1  But other sources close to the sale said Viven...   \n",
       "1  s_2  Micron has declared its first quarterly profit...   \n",
       "2  s_3  The fines are part of failed Republican effort...   \n",
       "3  s_4  The American Anglican Council, which represent...   \n",
       "4  s_5  The tech-loaded Nasdaq composite rose 20.96 po...   \n",
       "\n",
       "                                           Sentence2  Gold Tag  \\\n",
       "0  But other sources close to the sale said Viven...       4.0   \n",
       "1  Micron's numbers also marked the first quarter...       4.0   \n",
       "2  Perry said he backs the Senate's efforts, incl...       3.0   \n",
       "3  The American Anglican Council, which represent...       3.0   \n",
       "4  The technology-laced Nasdaq Composite Index <....       2.0   \n",
       "\n",
       "                                     tokenized_sent1  \\\n",
       "0  [But, other, sources, close, to, the, sale, sa...   \n",
       "1  [Micron, has, declared, its, first, quarterly,...   \n",
       "2  [The, fines, are, part, of, failed, Republican...   \n",
       "3  [The, American, Anglican, Council, ,, which, r...   \n",
       "4  [The, tech-loaded, Nasdaq, composite, rose, 20...   \n",
       "\n",
       "                                     tokenized_sent2  \\\n",
       "0  [But, other, sources, close, to, the, sale, sa...   \n",
       "1  [Micron, 's, numbers, also, marked, the, first...   \n",
       "2  [Perry, said, he, backs, the, Senate, 's, effo...   \n",
       "3  [The, American, Anglican, Council, ,, which, r...   \n",
       "4  [The, technology-laced, Nasdaq, Composite, Ind...   \n",
       "\n",
       "                                    lemmatized_sent1  \\\n",
       "0  [But, other, source, close, to, the, sale, sai...   \n",
       "1  [Micron, ha, declared, it, first, quarterly, p...   \n",
       "2  [The, fine, are, part, of, failed, Republican,...   \n",
       "3  [The, American, Anglican, Council, ,, which, r...   \n",
       "4  [The, tech-loaded, Nasdaq, composite, rose, 20...   \n",
       "\n",
       "                                    lemmatized_sent2  \\\n",
       "0  [But, other, source, close, to, the, sale, sai...   \n",
       "1  [Micron, 's, number, also, marked, the, first,...   \n",
       "2  [Perry, said, he, back, the, Senate, 's, effor...   \n",
       "3  [The, American, Anglican, Council, ,, which, r...   \n",
       "4  [The, technology-laced, Nasdaq, Composite, Ind...   \n",
       "\n",
       "                                           POS_Tags1  \\\n",
       "0  [(But, CC), (other, JJ), (source, NN), (close,...   \n",
       "1  [(Micron, NNP), (ha, NN), (declared, VBD), (it...   \n",
       "2  [(The, DT), (fine, NN), (are, VBP), (part, NN)...   \n",
       "3  [(The, DT), (American, JJ), (Anglican, NNP), (...   \n",
       "4  [(The, DT), (tech-loaded, JJ), (Nasdaq, NNP), ...   \n",
       "\n",
       "                                           POS_Tags2     Root1    Root2  \\\n",
       "0  [(But, CC), (other, JJ), (source, NN), (close,...      said     said   \n",
       "1  [(Micron, NNP), ('s, POS), (number, NN), (also...  declared   marked   \n",
       "2  [(Perry, NNP), (said, VBD), (he, PRP), (back, ...       are     said   \n",
       "3  [(The, DT), (American, JJ), (Anglican, NNP), (...      said     said   \n",
       "4  [(The, DT), (technology-laced, JJ), (Nasdaq, N...      rose  climbed   \n",
       "\n",
       "   flagCheckRoot  baseline_sim  word_align_sim   info_con_sim  tag_overlap  \\\n",
       "0           True      2.800000        0.740427   4.027374e+00     0.901961   \n",
       "1          False      3.000000        0.790476   5.430591e+00     0.400000   \n",
       "2          False      2.000000        0.652066   5.643231e+00     0.625000   \n",
       "3           True      4.722222        0.930556   7.816363e+00     0.772727   \n",
       "4          False      1.176471        0.562302  1.428571e+299     0.193548   \n",
       "\n",
       "   verb_diff  noun_diff  adj_diff  adv_diff  \\\n",
       "0   0.333333   0.076923  0.111111  0.333333   \n",
       "1   0.333333   0.333333  0.000000  1.000000   \n",
       "2   0.111111   0.000000  1.000000  0.000000   \n",
       "3   0.000000   0.285714  0.142857  0.000000   \n",
       "4   0.333333   0.230769  0.333333  0.000000   \n",
       "\n",
       "                                                 mmr   res_sim  no_ques_diff  \\\n",
       "0  [0.8269078095811264, 0.7994004396802319, 0.499...  2.549887             0   \n",
       "1  [0.6470795835539085, 1.0, 0.000999000999000999...  2.770720             0   \n",
       "2  [0.8500074996250188, 1000.9999999999999, 0, 1....  2.531463             0   \n",
       "3  [0.7000099996666778, 0.7500624843789052, 0, 0....  2.560187             0   \n",
       "4  [0.9990009990009991, 0.4999997502498749, 1000....  2.709486             0   \n",
       "\n",
       "   no_excl_diff                                     annotations_s1  \\\n",
       "0             0  {'URI': ['http://dbpedia.org/resource/Vivendi'...   \n",
       "1             0                           {'URI': [], 'types': []}   \n",
       "2             0  {'URI': ['http://dbpedia.org/resource/Republic...   \n",
       "3             0                           {'URI': [], 'types': []}   \n",
       "4             0  {'URI': ['http://dbpedia.org/resource/Nasdaq_C...   \n",
       "\n",
       "                                      annotations_s2  num_same_URI  \\\n",
       "0  {'URI': ['http://dbpedia.org/resource/Vivendi'...             0   \n",
       "1  {'URI': ['http://dbpedia.org/resource/Micron_T...             0   \n",
       "2  {'URI': ['http://dbpedia.org/resource/Perry', ...             1   \n",
       "3  {'URI': ['http://dbpedia.org/resource/American...             0   \n",
       "4  {'URI': ['http://dbpedia.org/resource/Nasdaq_C...             0   \n",
       "\n",
       "   overlap_types  common_entities  \n",
       "0       1.000000         0.333333  \n",
       "1       0.000000         1.000000  \n",
       "2       0.333333         0.333333  \n",
       "3       0.000000         0.333333  \n",
       "4       1.000000         0.250000  "
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init the Wordnet Lemmatizer\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenization\n",
    "train['tokenized_sent1'] = train.apply(lambda row: nltk.word_tokenize(row['Sentence1']), axis=1)\n",
    "train['tokenized_sent2'] = train.apply(lambda row: nltk.word_tokenize(row['Sentence2']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [But, source, close, sale, said, Vivendi, wa, ...\n",
       "1       [Micron, 's, number, also, marked, first, quar...\n",
       "2       [Perry, said, back, Senate, 's, effort, ,, inc...\n",
       "3       [The, American, Anglican, Council, ,, represen...\n",
       "4       [The, technology-laced, Nasdaq, Composite, Ind...\n",
       "5       [Shares, Allergan, 14, cent, $, 78.40, late, t...\n",
       "6       [More, 130, people, arrested, $, 17, million, ...\n",
       "7       [Albuquerque, Mayor, Martin, Chavez, said, inv...\n",
       "8       [The, scientist, also, quarantined, home, soon...\n",
       "9       [The, upgrade, available, free, download, curr...\n",
       "10      [A, Cuban, architect, wa, sentenced, 20, year,...\n",
       "11      [Jim, Williams, ,, director, US-VISIT, project...\n",
       "12      [The, hearing, came, one, day, Pentagon, first...\n",
       "13      [In, Nairobi, ,, provost, All, Saints, Cathedr...\n",
       "14      [Vermillion, ,, Posey, Madison, County, popula...\n",
       "15      [Swartz, sought, charge, dismissed, ,, saying,...\n",
       "16       [In, 1995, ,, last, survey, ,, number, equal, .]\n",
       "17      [The, federal, court, ruled, monument, violate...\n",
       "18      [They, underwent, test, weekend, ,, warded, Ra...\n",
       "19      [At, Casa, de, Espaa, ,, customer, eating, din...\n",
       "20      [The, panel, begin, formal, investigation, sta...\n",
       "21      [Frankel, said, Peace, Rules, run, Preakness, ...\n",
       "22      [The, charge, espionage, aiding, enemy, carry,...\n",
       "23      [The, broader, Standard, &, Poor, 's, 500, Ind...\n",
       "24      [Klarman, wa, charged, 16, count, wire, fraud, .]\n",
       "25      [It, may, dying, entrenched, interest, positio...\n",
       "26      [But, church, member, observer, say, anticipat...\n",
       "27      [Steve, Squyres, ,, Cornell, University, scien...\n",
       "28      [The, military, said, killed, 16, rebel, captu...\n",
       "29      [The, team, ha, named, sensor, Canary, ,, cell...\n",
       "                              ...                        \n",
       "1427    [The, right, government, remove, arbitrarily, ...\n",
       "1428    [Indeed, ,, convinced, definition, fair, price...\n",
       "1429    [The, labelling, beef, ha, decided, ,, minimum...\n",
       "1430    [It, happening, trial, 8, January, ., accused,...\n",
       "1431    [When, confronted, potential, risk, ,, importa...\n",
       "1432                [Question, No, 6, (, H-0886/00, ), :]\n",
       "1433    [In, 1996, ,, European, Parliament, favour, ba...\n",
       "1434    [An, evolution, made, strongly, dependent, bor...\n",
       "1435    [Mr, President, ,, Committee, Citizens, ', Fre...\n",
       "1436                             [The, debate, closed, .]\n",
       "1437    [I, also, voted, text, call, incorporation, Ch...\n",
       "1438    [You, even, want, incorporate, Treaty, ,, show...\n",
       "1439    [As, European, Parliament, called, resolution,...\n",
       "1440    [All, currently, work, black, would, obtain, e...\n",
       "1441    [We, need, know, today, ,, since, always, unce...\n",
       "1442    [-, (, ES, ), Mr, President, ,, enlargement, e...\n",
       "1443    [There, urgency, therefore, decided, put, poin...\n",
       "1444    [The, resolution, Nice, Summit, ,, ha, passed,...\n",
       "1445    [This, Parliament, ha, ,, however, ,, also, fo...\n",
       "1446            [Approval, Minutes, previous, sitting, .]\n",
       "1447    [Faced, criticism, ,, particularly, Ireland, F...\n",
       "1448    [It, cross, 8, January, year, ., Union, Tunisi...\n",
       "1449    [If, create, clear, framework, binding, Member...\n",
       "1450    [And, I, say, clearly, :, need, give, opportun...\n",
       "1451    [The, annual, report, designed, identify, pote...\n",
       "1452          [It, urgent, decided, put, item, agenda, .]\n",
       "1453    [We, actually, want, better, ,, I, think, quit...\n",
       "1454        [(, Parliament, accepted, oral, amendment, )]\n",
       "1455    [My, party, serious, reservation, regulation, ...\n",
       "1456                   [He, drove, rose, colored, car, .]\n",
       "Name: lemmatized_sent2, Length: 1455, dtype: object"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lemmatization\n",
    "def lemmatize(s):\n",
    "  \n",
    "    s = [lemmatizer.lemmatize(word) for word in s]\n",
    "    return s\n",
    "    \n",
    "train['lemmatized_sent1'] = train.apply(lambda row: lemmatize(row['tokenized_sent1']), axis=1)\n",
    "train['lemmatized_sent2'] = train.apply(lambda row: lemmatize(row['tokenized_sent2']), axis=1)\n",
    "\n",
    "#stop words\n",
    "stop = stopwords.words('english')\n",
    "train['lemmatized_sent1'].apply(lambda x: [item for item in x if item not in stop])\n",
    "train['lemmatized_sent2'].apply(lambda x: [item for item in x if item not in stop])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['POS_Tags1'] = train.apply(lambda row: nltk.pos_tag(row['lemmatized_sent1']), axis=1)\n",
    "train['POS_Tags2'] = train.apply(lambda row: nltk.pos_tag(row['lemmatized_sent2']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dependency_parse(sentence):\n",
    "    doc=nlp(sentence)\n",
    "    for token in doc:    \n",
    "        if(token.dep_==\"ROOT\"):\n",
    "            return lemmatizer.lemmatize(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Root1'] = train.apply(lambda row: dependency_parse(row['Sentence1']), axis=1)\n",
    "train['Root2'] = train.apply(lambda row: dependency_parse(row['Sentence2']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['flagCheckRoot'] = train.apply(lambda row: row['Root1']==row['Root2'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========== util func ==============\n",
    "def penn_to_wn(tag):\n",
    "    \"\"\" Convert between a Penn Treebank tag to a simplified Wordnet tag \"\"\"\n",
    "    if tag.startswith('N'): return 'n'\n",
    "    if tag.startswith('V'): return 'v'\n",
    "    if tag.startswith('J'): return 'a'\n",
    "    if tag.startswith('R'): return 'r'\n",
    "    return None\n",
    " \n",
    "def tagged_to_synset(word, tag):\n",
    "    wn_tag = penn_to_wn(tag)\n",
    "    if wn_tag is None:\n",
    "        return None\n",
    "    try:\n",
    "        return wn.synsets(word, wn_tag)[0]\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "notin_cnt = [0]\n",
    "# =========== feature extraction ==============\n",
    "def sentence_similarity_word_alignment(sentence1, sentence2):\n",
    "    \"\"\" compute the sentence similarity using Wordnet and ppdb \"\"\"\n",
    "    # Tokenize and tag\n",
    "    sentence1 = pos_tag(word_tokenize(sentence1))\n",
    "    sentence2 = pos_tag(word_tokenize(sentence2)) \n",
    "    # Get the synsets for the tagged words\n",
    "    synsets1 = [tagged_to_synset(*tagged_word) for tagged_word in sentence1]\n",
    "    synsets2 = [tagged_to_synset(*tagged_word) for tagged_word in sentence2]\n",
    "    # Filter out the Nones\n",
    "    synsets1 = [ss for ss in synsets1 if ss]\n",
    "    synsets2 = [ss for ss in synsets2 if ss]\n",
    "    score, count = 0.0, 0\n",
    "    ppdb_score, align_cnt = 0, 0\n",
    "    # For each word in the first sentence\n",
    "    for synset in synsets1:\n",
    "        # Get the similarity value of the most similar word in the other sentence\n",
    "        L = [synset.path_similarity(ss) for ss in synsets2]\n",
    "        L_prime = L\n",
    "        L = [l for l in L if l]\n",
    "\n",
    "      \n",
    "\n",
    "        if L: \n",
    "            best_score = max(L)\n",
    "            score += best_score\n",
    "            count += 1\n",
    "    # Average the values\n",
    "    if count >0: score /= count\n",
    "\n",
    "    return score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_similarity_simple_baseline(s1, s2,counts = None):\n",
    "    def embedding_count(s):\n",
    "        ret_embedding = defaultdict(int)\n",
    "        for w in s.split():\n",
    "            w = w.strip('?.,')\n",
    "            ret_embedding[w] += 1\n",
    "        return ret_embedding\n",
    "    first_sent_embedding = embedding_count(s1)\n",
    "    second_sent_embedding = embedding_count(s2)\n",
    "    Embedding1 = []\n",
    "    Embedding2 = []\n",
    "    if counts:\n",
    "        for w in first_sent_embedding:\n",
    "            Embedding1.append(first_sent_embedding[w] * 1.0/ (counts[w]+0.001))\n",
    "            Embedding2.append(second_sent_embedding[w] *1.0/ (counts[w]+0.001))\n",
    "    else:\n",
    "        for w in first_sent_embedding:\n",
    "            Embedding1.append(first_sent_embedding[w])\n",
    "            Embedding2.append(second_sent_embedding[w])\n",
    "    ret_score = 0\n",
    "    if not 0 == sum(Embedding2): \n",
    "      \n",
    "        sm= difflib.SequenceMatcher(None,Embedding1,Embedding2)\n",
    "        ret_score = sm.ratio()*5 \n",
    "    return ret_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_overlap_pen(s1, s2):\n",
    "    \"\"\"\n",
    "    :param s1:\n",
    "    :param s2:\n",
    "    :return: overlap_pen score\n",
    "    \"\"\"\n",
    "    ss1 = s1.strip().split()\n",
    "    ss2 = s2.strip().split()\n",
    "    ovlp_cnt = 0\n",
    "    for w1 in ss1:\n",
    "        ovlp_cnt += ss2.count(w1)\n",
    "    score = 2 * ovlp_cnt / (len(ss1) + len(ss2) + .0)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_token_diff(s1,s2):\n",
    "    s1, s2 = word_tokenize(s1), word_tokenize(s2)\n",
    "    pos1, pos2 = pos_tag(s1), pos_tag(s2)\n",
    "    # all tokens\n",
    "    return  abs(len(s1) - len(s2)) / float(len(s1) + len(s2))\n",
    "\n",
    "def adj_diff(s1,s2):\n",
    "    s1, s2 = word_tokenize(s1), word_tokenize(s2)\n",
    "    pos1, pos2 = pos_tag(s1), pos_tag(s2)\n",
    "    # all tokens\n",
    "    cnt1 = len([1 for item in pos1 if item[1].startswith('J')])\n",
    "    cnt2 = len([1 for item in pos2 if item[1].startswith('J')])\n",
    "    if cnt1 == 0 and cnt2 == 0:\n",
    "        t2 = 0\n",
    "    else:\n",
    "        t2 = abs(cnt1 - cnt2) / float(cnt1 + cnt2)\n",
    "        \n",
    "    return t2\n",
    "\n",
    "def adv_diff(s1,s2):\n",
    "    s1, s2 = word_tokenize(s1), word_tokenize(s2)\n",
    "    pos1, pos2 = pos_tag(s1), pos_tag(s2)\n",
    "    cnt1 = len([1 for item in pos1 if item[1].startswith('R')])\n",
    "    cnt2 = len([1 for item in pos2 if item[1].startswith('R')])\n",
    "    if cnt1 == 0 and cnt2 == 0:\n",
    "        t3 = 0\n",
    "    else:\n",
    "        t3 = abs(cnt1 - cnt2) / float(cnt1 + cnt2)\n",
    "        \n",
    "    return t3\n",
    "\n",
    "\n",
    "def noun_diff(s1,s2):\n",
    "    s1, s2 = word_tokenize(s1), word_tokenize(s2)\n",
    "    pos1, pos2 = pos_tag(s1), pos_tag(s2)\n",
    "    # all nouns\n",
    "    cnt1 = len([1 for item in pos1 if item[1].startswith('N')])\n",
    "    cnt2 = len([1 for item in pos2 if item[1].startswith('N')])\n",
    "    if cnt1 == 0 and cnt2 == 0:\n",
    "        t4 = 0\n",
    "    else:\n",
    "        t4 = abs(cnt1 - cnt2) / float(cnt1 + cnt2)\n",
    "        \n",
    "    return t4\n",
    "\n",
    "def verb_diff(s1,s2):\n",
    "    s1, s2 = word_tokenize(s1), word_tokenize(s2)\n",
    "    pos1, pos2 = pos_tag(s1), pos_tag(s2)\n",
    "    # all verbs\n",
    "    cnt1 = len([1 for item in pos1 if item[1].startswith('V')])\n",
    "    cnt2 = len([1 for item in pos2 if item[1].startswith('V')])\n",
    "    if cnt1 == 0 and cnt2 == 0:\n",
    "        t5 = 0\n",
    "    else:\n",
    "        t5 = abs(cnt1 - cnt2) / float(cnt1 + cnt2)\n",
    "    return t5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def extract_mmr_t(s1, s2):\n",
    "    shorter = 1\n",
    "    if(len(s1) > len(s2)):  shorter = 2\n",
    "\n",
    "    s1, s2 = word_tokenize(s1), word_tokenize(s2)\n",
    "    pos1, pos2 = pos_tag(s1), pos_tag(s2)\n",
    "    # all tokens\n",
    "    t1 = (len(s1)+0.001) / (len(s2) +0.001)\n",
    "    # all adjectives\n",
    "    cnt1 = len([1 for item in pos1 if item[1].startswith('J')])\n",
    "    cnt2 = len([1 for item in pos2 if item[1].startswith('J')])\n",
    "    if cnt1 == 0 and cnt2 == 0:\n",
    "        t2 = 0\n",
    "    else:\n",
    "        t2 = (cnt1 +0.001) / (cnt2 + 0.001)\n",
    "    # all adverbs\n",
    "    cnt1 = len([1 for item in pos1 if item[1].startswith('R')])\n",
    "    cnt2 = len([1 for item in pos2 if item[1].startswith('R')])\n",
    "    if cnt1 == 0 and cnt2 == 0:\n",
    "        t3 = 0\n",
    "    else:\n",
    "        t3 = (cnt1 +0.001) / (cnt2+0.001)\n",
    "    # all nouns\n",
    "    cnt1 = len([1 for item in pos1 if item[1].startswith('N')])\n",
    "    cnt2 = len([1 for item in pos2 if item[1].startswith('N')])\n",
    "    if cnt1 == 0 and cnt2 == 0:\n",
    "        t4 = 0\n",
    "    else:\n",
    "        t4 = (cnt1 +0.001) / (cnt2 +0.001)\n",
    "    # all verbs\n",
    "    cnt1 = len([1 for item in pos1 if item[1].startswith('V')])\n",
    "    cnt2 = len([1 for item in pos2 if item[1].startswith('V')])\n",
    "    if cnt1 == 0 and cnt2 == 0:\n",
    "        t5 = 0\n",
    "    else:\n",
    "        t5 = (cnt1+ 0.001) / (cnt2 + 0.001)\n",
    "\n",
    "    if shorter == 2:\n",
    "        t1 = 1 / (t1 + 0.001)\n",
    "        t2 = 1 / (t2 + 0.001)\n",
    "        t3 = 1 / (t3 + 0.001)\n",
    "        t4 = 1 / (t4 + 0.001)\n",
    "        t5 = 1 / (t5 + 0.001)\n",
    "\n",
    "    return [t1, t2, t3, t4, t5]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_similarity_information_content(sentence1, sentence2):\n",
    "\n",
    "    ''' compute the sentence similairty using information content from wordnet '''\n",
    "    # Tokenize and tag\n",
    "    sentence1 = pos_tag(word_tokenize(sentence1))\n",
    "    sentence2 = pos_tag(word_tokenize(sentence2)) \n",
    "    # Get the synsets for the tagged words\n",
    "    synsets1 = [tagged_to_synset(*tagged_word) for tagged_word in sentence1]\n",
    "    synsets2 = [tagged_to_synset(*tagged_word) for tagged_word in sentence2]\n",
    "    # Filter out the Nones\n",
    "    synsets1 = [ss for ss in synsets1 if ss]\n",
    "    synsets2 = [ss for ss in synsets2 if ss]\n",
    "    score, count = 0.0, 0\n",
    "    ppdb_score, align_cnt = 0, 0\n",
    "    # For each word in the first sentence\n",
    "    for synset in synsets1:\n",
    "        L = []\n",
    "        for ss in synsets2:\n",
    "            try:\n",
    "                L.append(synset.res_similarity(ss, brown_ic))\n",
    "            except:\n",
    "                continue\n",
    "        if L: \n",
    "            best_score = max(L)\n",
    "            score += best_score\n",
    "            count += 1\n",
    "    # Average the values\n",
    "    if count >0: score /= count\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec1 = KeyedVectors.load_word2vec_format(\"GoogleNews-vectors-negative300.bin\", binary=True)\n",
    "vec2 = KeyedVectors.load_word2vec_format(\"GoogleNews-vectors-negative300.bin\", binary=True)\n",
    "\n",
    "def extract_res_vec_similarity(s1, s2):\n",
    "    first_sents_embeddings = np.empty([0,300])\n",
    "    second_sents_embeddings = np.empty([0,300])\n",
    "\n",
    "    first_vecs = np.array([])\n",
    "    for w in s1.split():\n",
    "        w = w.strip('?.,')\n",
    "        if w in vec1:\n",
    "            first_vec = np.array([vec1[w]])\n",
    "            if first_vecs.shape[0] == 0:\n",
    "                first_vecs = first_vec\n",
    "            else:\n",
    "                first_vecs = np.vstack((first_vecs, first_vec))\n",
    "        else:\n",
    "            if first_vecs.shape[0] == 0:\n",
    "                first_vecs = np.random.normal(0, 5, 300)\n",
    "            else:\n",
    "                first_vecs = np.vstack((first_vecs, np.random.normal(0, 5, 300)))\n",
    "        # print(\"first \")\n",
    "        # print(first_vecs.shape)\n",
    "    if(first_vecs.shape == (300, )):\n",
    "        temp = first_vecs\n",
    "    else:\n",
    "        temp = np.mean(first_vecs, axis=0)\n",
    "    # print(temp.shape)\n",
    "    first_sents_embeddings = np.append(first_sents_embeddings, [temp], axis=0)\n",
    "\n",
    "    second_vecs = np.array([])  \n",
    "    for w in s2.split():\n",
    "        w = w.strip('?.,')\n",
    "        if w in vec2:\n",
    "            second_vec = np.array([vec2[w]])\n",
    "            if second_vecs.shape[0] == 0:\n",
    "                second_vecs = second_vec\n",
    "            else:\n",
    "                second_vecs = np.vstack((second_vecs, second_vec))\n",
    "        else:\n",
    "            if second_vecs.shape[0] == 0:\n",
    "                second_vecs = np.random.normal(0, 5, 300)\n",
    "            else:\n",
    "                second_vecs = np.vstack((second_vecs, np.random.normal(0, 5, 300)))\n",
    "        # print(\"second \")\n",
    "        # print(second_vecs.shape)\n",
    "    if(second_vecs.shape == (300,)):\n",
    "        temp = second_vecs\n",
    "    else:\n",
    "        temp = np.mean(second_vecs, axis=0)\n",
    "    # print(temp.shape)\n",
    "    second_sents_embeddings = np.append(second_sents_embeddings, [temp], axis=0)\n",
    "\n",
    "    for i in range(len(first_sents_embeddings)):\n",
    "        # cosine similarity\n",
    "\n",
    "        ret = np.dot(first_sents_embeddings[i], second_sents_embeddings[i]) / (np.linalg.norm(first_sents_embeddings[i]) * np.linalg.norm(second_sents_embeddings[i]))\n",
    "        ret = 5*(ret + 1) / 2\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_doc2vec_similarity(s1,s2, model):\n",
    "    s1 = [w.strip('?.,') for w in s1.split()]\n",
    "    s2 = [w.strip('?.,') for w in s2.split()]\n",
    "    embed1 = model.infer_vector(s1)\n",
    "    embed2 = model.infer_vector(s2)\n",
    "    ret = np.dot(embed1,embed2)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Sentence1</th>\n",
       "      <th>Sentence2</th>\n",
       "      <th>Gold Tag</th>\n",
       "      <th>tokenized_sent1</th>\n",
       "      <th>tokenized_sent2</th>\n",
       "      <th>lemmatized_sent1</th>\n",
       "      <th>lemmatized_sent2</th>\n",
       "      <th>POS_Tags1</th>\n",
       "      <th>POS_Tags2</th>\n",
       "      <th>Root1</th>\n",
       "      <th>Root2</th>\n",
       "      <th>flagCheckRoot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s_1</td>\n",
       "      <td>But other sources close to the sale said Viven...</td>\n",
       "      <td>But other sources close to the sale said Viven...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[But, other, sources, close, to, the, sale, sa...</td>\n",
       "      <td>[But, other, sources, close, to, the, sale, sa...</td>\n",
       "      <td>[But, other, source, close, to, the, sale, sai...</td>\n",
       "      <td>[But, other, source, close, to, the, sale, sai...</td>\n",
       "      <td>[(But, CC), (other, JJ), (source, NN), (close,...</td>\n",
       "      <td>[(But, CC), (other, JJ), (source, NN), (close,...</td>\n",
       "      <td>said</td>\n",
       "      <td>said</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s_2</td>\n",
       "      <td>Micron has declared its first quarterly profit...</td>\n",
       "      <td>Micron's numbers also marked the first quarter...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[Micron, has, declared, its, first, quarterly,...</td>\n",
       "      <td>[Micron, 's, numbers, also, marked, the, first...</td>\n",
       "      <td>[Micron, ha, declared, it, first, quarterly, p...</td>\n",
       "      <td>[Micron, 's, number, also, marked, the, first,...</td>\n",
       "      <td>[(Micron, NNP), (ha, NN), (declared, VBD), (it...</td>\n",
       "      <td>[(Micron, NNP), ('s, POS), (number, NN), (also...</td>\n",
       "      <td>declared</td>\n",
       "      <td>marked</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s_3</td>\n",
       "      <td>The fines are part of failed Republican effort...</td>\n",
       "      <td>Perry said he backs the Senate's efforts, incl...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[The, fines, are, part, of, failed, Republican...</td>\n",
       "      <td>[Perry, said, he, backs, the, Senate, 's, effo...</td>\n",
       "      <td>[The, fine, are, part, of, failed, Republican,...</td>\n",
       "      <td>[Perry, said, he, back, the, Senate, 's, effor...</td>\n",
       "      <td>[(The, DT), (fine, NN), (are, VBP), (part, NN)...</td>\n",
       "      <td>[(Perry, NNP), (said, VBD), (he, PRP), (back, ...</td>\n",
       "      <td>are</td>\n",
       "      <td>said</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s_4</td>\n",
       "      <td>The American Anglican Council, which represent...</td>\n",
       "      <td>The American Anglican Council, which represent...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[The, American, Anglican, Council, ,, which, r...</td>\n",
       "      <td>[The, American, Anglican, Council, ,, which, r...</td>\n",
       "      <td>[The, American, Anglican, Council, ,, which, r...</td>\n",
       "      <td>[The, American, Anglican, Council, ,, which, r...</td>\n",
       "      <td>[(The, DT), (American, JJ), (Anglican, NNP), (...</td>\n",
       "      <td>[(The, DT), (American, JJ), (Anglican, NNP), (...</td>\n",
       "      <td>said</td>\n",
       "      <td>said</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s_5</td>\n",
       "      <td>The tech-loaded Nasdaq composite rose 20.96 po...</td>\n",
       "      <td>The technology-laced Nasdaq Composite Index &lt;....</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[The, tech-loaded, Nasdaq, composite, rose, 20...</td>\n",
       "      <td>[The, technology-laced, Nasdaq, Composite, Ind...</td>\n",
       "      <td>[The, tech-loaded, Nasdaq, composite, rose, 20...</td>\n",
       "      <td>[The, technology-laced, Nasdaq, Composite, Ind...</td>\n",
       "      <td>[(The, DT), (tech-loaded, JJ), (Nasdaq, NNP), ...</td>\n",
       "      <td>[(The, DT), (technology-laced, JJ), (Nasdaq, N...</td>\n",
       "      <td>rose</td>\n",
       "      <td>climbed</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                          Sentence1  \\\n",
       "0  s_1  But other sources close to the sale said Viven...   \n",
       "1  s_2  Micron has declared its first quarterly profit...   \n",
       "2  s_3  The fines are part of failed Republican effort...   \n",
       "3  s_4  The American Anglican Council, which represent...   \n",
       "4  s_5  The tech-loaded Nasdaq composite rose 20.96 po...   \n",
       "\n",
       "                                           Sentence2  Gold Tag  \\\n",
       "0  But other sources close to the sale said Viven...       4.0   \n",
       "1  Micron's numbers also marked the first quarter...       4.0   \n",
       "2  Perry said he backs the Senate's efforts, incl...       3.0   \n",
       "3  The American Anglican Council, which represent...       3.0   \n",
       "4  The technology-laced Nasdaq Composite Index <....       2.0   \n",
       "\n",
       "                                     tokenized_sent1  \\\n",
       "0  [But, other, sources, close, to, the, sale, sa...   \n",
       "1  [Micron, has, declared, its, first, quarterly,...   \n",
       "2  [The, fines, are, part, of, failed, Republican...   \n",
       "3  [The, American, Anglican, Council, ,, which, r...   \n",
       "4  [The, tech-loaded, Nasdaq, composite, rose, 20...   \n",
       "\n",
       "                                     tokenized_sent2  \\\n",
       "0  [But, other, sources, close, to, the, sale, sa...   \n",
       "1  [Micron, 's, numbers, also, marked, the, first...   \n",
       "2  [Perry, said, he, backs, the, Senate, 's, effo...   \n",
       "3  [The, American, Anglican, Council, ,, which, r...   \n",
       "4  [The, technology-laced, Nasdaq, Composite, Ind...   \n",
       "\n",
       "                                    lemmatized_sent1  \\\n",
       "0  [But, other, source, close, to, the, sale, sai...   \n",
       "1  [Micron, ha, declared, it, first, quarterly, p...   \n",
       "2  [The, fine, are, part, of, failed, Republican,...   \n",
       "3  [The, American, Anglican, Council, ,, which, r...   \n",
       "4  [The, tech-loaded, Nasdaq, composite, rose, 20...   \n",
       "\n",
       "                                    lemmatized_sent2  \\\n",
       "0  [But, other, source, close, to, the, sale, sai...   \n",
       "1  [Micron, 's, number, also, marked, the, first,...   \n",
       "2  [Perry, said, he, back, the, Senate, 's, effor...   \n",
       "3  [The, American, Anglican, Council, ,, which, r...   \n",
       "4  [The, technology-laced, Nasdaq, Composite, Ind...   \n",
       "\n",
       "                                           POS_Tags1  \\\n",
       "0  [(But, CC), (other, JJ), (source, NN), (close,...   \n",
       "1  [(Micron, NNP), (ha, NN), (declared, VBD), (it...   \n",
       "2  [(The, DT), (fine, NN), (are, VBP), (part, NN)...   \n",
       "3  [(The, DT), (American, JJ), (Anglican, NNP), (...   \n",
       "4  [(The, DT), (tech-loaded, JJ), (Nasdaq, NNP), ...   \n",
       "\n",
       "                                           POS_Tags2     Root1    Root2  \\\n",
       "0  [(But, CC), (other, JJ), (source, NN), (close,...      said     said   \n",
       "1  [(Micron, NNP), ('s, POS), (number, NN), (also...  declared   marked   \n",
       "2  [(Perry, NNP), (said, VBD), (he, PRP), (back, ...       are     said   \n",
       "3  [(The, DT), (American, JJ), (Anglican, NNP), (...      said     said   \n",
       "4  [(The, DT), (technology-laced, JJ), (Nasdaq, N...      rose  climbed   \n",
       "\n",
       "   flagCheckRoot  \n",
       "0           True  \n",
       "1          False  \n",
       "2          False  \n",
       "3           True  \n",
       "4          False  "
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create count dictionary\n",
    "\n",
    "Counts_for_tf = defaultdict(int)\n",
    "\n",
    "for sent in train['Sentence1'].tolist():\n",
    "    for w in [w.strip(\"?.,\") for w in sent.split()]: Counts_for_tf[w] += 1\n",
    "for sent in train['Sentence2'].tolist():\n",
    "    for w in [w.strip(\"?.,\") for w in sent.split()]: Counts_for_tf[w] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['baseline_sim']=train.apply(lambda row: sentence_similarity_simple_baseline(row['Sentence1'],row['Sentence2'],Counts_for_tf), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['word_align_sim']=train.apply(lambda row: sentence_similarity_word_alignment(row['Sentence1'],row['Sentence2']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['info_con_sim']=train.apply(lambda row: sentence_similarity_information_content(row['Sentence1'],row['Sentence2']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['tag_overlap']=train.apply(lambda row: extract_overlap_pen(row['Sentence1'],row['Sentence2']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['verb_diff']=train.apply(lambda row: verb_diff(row['Sentence1'],row['Sentence2']), axis=1)\n",
    "train['noun_diff']=train.apply(lambda row: noun_diff(row['Sentence1'],row['Sentence2']), axis=1)\n",
    "train['adj_diff']=train.apply(lambda row: adj_diff(row['Sentence1'],row['Sentence2']), axis=1)\n",
    "train['adv_diff']=train.apply(lambda row: adv_diff(row['Sentence1'],row['Sentence2']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['mmr']=train.apply(lambda row: extract_mmr_t(row['Sentence1'],row['Sentence2']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['res_sim']=train.apply(lambda row: extract_res_vec_similarity(row['Sentence1'],row['Sentence2']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['no_ques_diff']=train.apply(lambda row: (row['Sentence1'].count(\"?\")-row['Sentence2'].count(\"?\")), axis=1)\n",
    "train['no_excl_diff']=train.apply(lambda row: (row['Sentence1'].count(\"!\")-row['Sentence2'].count(\"!\")), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def duplicates(value1,value2):\n",
    "    \n",
    "    dups = Counter(value1) - Counter(value2)\n",
    "    return len(dups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_annotation(text):\n",
    "   # print(text)\n",
    "    try:\n",
    "        annotations = spotlight.annotate('http://api.dbpedia-spotlight.org/en/annotate',text,\n",
    "                              confidence=0.4, support=20)\n",
    "    except Exception as e:\n",
    "       # print(e)\n",
    "        return {'URI':[],'types':[]}\n",
    "    \n",
    "    URI_lst=[]\n",
    "    types_lst=[]\n",
    "    \n",
    "    for ann_dict in annotations:\n",
    "        URI_lst.append(ann_dict['URI'])\n",
    "        types_lst.append(ann_dict['types'])\n",
    "    \n",
    "    return {'URI':URI_lst,'types':types_lst}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['annotations_s1'] = train.apply(lambda row: get_annotation(row['Sentence1']), axis=1)\n",
    "train['annotations_s2'] = train.apply(lambda row: get_annotation(row['Sentence2']), axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_common_types(sent1_types,sent2_types):\n",
    "    s1=set(sent1_types)\n",
    "    s2=set(sent2_types)\n",
    "    if len(s1.union(s2))>0:\n",
    "        return len(s1.intersection(s2))/len(s1.union(s2))\n",
    "    return 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NER features\n",
    "\n",
    "train['num_same_URI'] = train.apply(lambda row: duplicates(row['annotations_s1']['URI'],row['annotations_s2']['URI']), axis=1)\n",
    "# NER features\n",
    "\n",
    "train['overlap_types'] = train.apply(lambda row:get_common_types(row['annotations_s1']['types'],row['annotations_s2']['types']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_common_entities(text1,text2):\n",
    "    doc1 = nlp(text1)\n",
    "    doc2 = nlp(text2)\n",
    "    ent1={X.label_  for X in doc1.ents}\n",
    "    ent2={X.label_  for X in doc2.ents}\n",
    "    if len(ent1.union(ent2))>0:\n",
    "        return len(ent1.intersection(ent2))/len(ent1.union(ent2))\n",
    "    return 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['common_entities'] = train.apply(lambda row: get_common_entities(row['Sentence1'],row['Sentence2']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'Sentence1', 'Sentence2', 'Gold Tag', 'tokenized_sent1',\n",
      "       'tokenized_sent2', 'lemmatized_sent1', 'lemmatized_sent2', 'POS_Tags1',\n",
      "       'POS_Tags2', 'Root1', 'Root2', 'flagCheckRoot', 'baseline_sim',\n",
      "       'word_align_sim', 'info_con_sim', 'tag_overlap', 'verb_diff',\n",
      "       'noun_diff', 'adj_diff', 'adv_diff', 'mmr', 'res_sim', 'no_ques_diff',\n",
      "       'no_excl_diff', 'annotations_s1', 'annotations_s2', 'num_same_URI',\n",
      "       'overlap_types', 'common_entities'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X=train[[ 'baseline_sim','Sentence1','Sentence2',\n",
    "       'word_align_sim', 'info_con_sim', 'tag_overlap', 'res_sim', 'no_ques_diff', 'no_excl_diff', 'num_same_URI', 'overlap_types','common_entities', 'verb_diff', 'noun_diff', 'adj_diff', 'adv_diff']]\n",
    "Y = train.loc[:, 'Gold Tag']\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create  corpus\n",
    "all_corpus=train['Sentence1'].tolist()+train['Sentence2'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classes to return text and numeric values for transformer\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class TextSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, field):\n",
    "        self.field = field\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.field]\n",
    "class NumberSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, field):\n",
    "        self.field = field\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[[self.field]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Tokenizer(str_input):\n",
    "    words = re.sub(r\"[^A-Za-z0-9\\-]\", \" \", str_input).lower().split()\n",
    "    return lemmatize(words)\n",
    "from sklearn.svm import SVR, LinearSVR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "        ('tfidf1', Pipeline([\n",
    "            ('colext', TextSelector('Sentence1')),\n",
    "            ('tfidf', TfidfVectorizer(tokenizer=Tokenizer, stop_words=stop_words,\n",
    "                     min_df=.0025, max_df=0.25, ngram_range=(1,2))),\n",
    "            ('svd', TruncatedSVD(algorithm='randomized', n_components=300)), \n",
    "        ])),\n",
    "       ('tfidf2', Pipeline([\n",
    "            ('colext', TextSelector('Sentence2')),\n",
    "            ('tfidf', TfidfVectorizer(tokenizer=Tokenizer, stop_words=stop_words,\n",
    "                     min_df=.0025, max_df=0.25, ngram_range=(1,2))),\n",
    "            ('svd', TruncatedSVD(algorithm='randomized', n_components=300)), \n",
    "        ])),\n",
    "        ('no_ques_diff', Pipeline([\n",
    "            ('wordext', NumberSelector('no_ques_diff')),\n",
    "            ('wscaler', StandardScaler()),\n",
    "        ])),\n",
    "         ('no_excl_diff', Pipeline([\n",
    "            ('wordext', NumberSelector('no_excl_diff')),\n",
    "            ('wscaler', StandardScaler()),\n",
    "        ])),\n",
    "         ('baseline_sim', Pipeline([\n",
    "            ('wordext', NumberSelector('baseline_sim')),\n",
    "            ('wscaler', StandardScaler()),\n",
    "        ])),\n",
    "         ('word_align_sim', Pipeline([\n",
    "            ('wordext', NumberSelector('word_align_sim')),\n",
    "            ('wscaler', StandardScaler()),\n",
    "        ])),\n",
    "         ('res_sim', Pipeline([\n",
    "            ('wordext', NumberSelector('res_sim')),\n",
    "            ('wscaler', StandardScaler()),\n",
    "        ])),\n",
    "         ('num_same_URI', Pipeline([\n",
    "            ('wordext', NumberSelector('num_same_URI')),\n",
    "            ('wscaler', StandardScaler()),\n",
    "        ])),\n",
    "           ('common_entities', Pipeline([\n",
    "            ('wordext', NumberSelector('common_entities')),\n",
    "        \n",
    "        ])),\n",
    "           ('verb_diff', Pipeline([\n",
    "            ('wordext', NumberSelector('verb_diff')),\n",
    "        \n",
    "        ])),\n",
    "         ('noun_diff', Pipeline([\n",
    "            ('wordext', NumberSelector('noun_diff')),\n",
    "        \n",
    "        ])),\n",
    "        ('adj_diff', Pipeline([\n",
    "            ('wordext', NumberSelector('adj_diff')),\n",
    "        \n",
    "        ])),\n",
    "        ('adv_diff', Pipeline([\n",
    "            ('wordext', NumberSelector('adv_diff')),\n",
    "        \n",
    "        ])),\n",
    "         ('overlap_types', Pipeline([\n",
    "            ('wordext', NumberSelector('overlap_types')),\n",
    "           \n",
    "        ])),\n",
    "           ('tag_overlap', Pipeline([\n",
    "            ('wordext', NumberSelector('tag_overlap')),\n",
    "           \n",
    "        ]))\n",
    "    ])),\n",
    "#    ('clf', XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.1)),\n",
    "  # ('rf', RandomForestClassifier()),\n",
    "  ('svr',SVR(kernel='linear')),\n",
    "     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kadss\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['doe', 'ha', 'wa'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('features',\n",
       "                 FeatureUnion(n_jobs=None,\n",
       "                              transformer_list=[('tfidf1',\n",
       "                                                 Pipeline(memory=None,\n",
       "                                                          steps=[('colext',\n",
       "                                                                  TextSelector(field='Sentence1')),\n",
       "                                                                 ('tfidf',\n",
       "                                                                  TfidfVectorizer(analyzer='word',\n",
       "                                                                                  binary=False,\n",
       "                                                                                  decode_error='strict',\n",
       "                                                                                  dtype=<class 'numpy.float64'>,\n",
       "                                                                                  encoding='utf-8',\n",
       "                                                                                  input='content',\n",
       "                                                                                  lowercase=True,\n",
       "                                                                                  max_df=0.25,\n",
       "                                                                                  max_features=None,\n",
       "                                                                                  min...\n",
       "                                                                  NumberSelector(field='overlap_types'))],\n",
       "                                                          verbose=False)),\n",
       "                                                ('tag_overlap',\n",
       "                                                 Pipeline(memory=None,\n",
       "                                                          steps=[('wordext',\n",
       "                                                                  NumberSelector(field='tag_overlap'))],\n",
       "                                                          verbose=False))],\n",
       "                              transformer_weights=None, verbose=False)),\n",
       "                ('svr',\n",
       "                 SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1,\n",
       "                     gamma='auto_deprecated', kernel='linear', max_iter=-1,\n",
       "                     shrinking=True, tol=0.001, verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preds = classifier.predict(X_test)\n",
    "\n",
    "\n",
    "preds = [ round(elem) for elem in preds ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.521978021978022\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         2\n",
      "         1.0       1.00      0.14      0.25         7\n",
      "         2.0       0.36      0.25      0.29        20\n",
      "         3.0       0.40      0.44      0.42        75\n",
      "         4.0       0.54      0.60      0.57       161\n",
      "         5.0       0.60      0.53      0.56        99\n",
      "\n",
      "    accuracy                           0.52       364\n",
      "   macro avg       0.65      0.49      0.52       364\n",
      "weighted avg       0.53      0.52      0.52       364\n",
      "\n",
      "[[ 2  0  0  0  0  0]\n",
      " [ 0  1  3  1  2  0]\n",
      " [ 0  0  5 10  5  0]\n",
      " [ 0  0  3 33 31  8]\n",
      " [ 0  0  3 35 97 26]\n",
      " [ 0  0  0  3 44 52]]\n",
      "F1-Score: 0.5183510310383672\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "from sklearn.metrics import accuracy_score, precision_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "print(\"Accuracy:\", accuracy_score(y_test, preds))\n",
    "print(classification_report(y_test, preds))\n",
    "print(confusion_matrix(y_test, preds))\n",
    "print(\"F1-Score:\",f1_score(y_test, preds, average='weighted')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6499291033442438, 4.584129571020399e-45)"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "stats.pearsonr(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "key=['p_'+str(i) for i in range(1,len(preds))]\n",
    "devList =  list(zip(key,preds))\n",
    "predList =  list(zip(key,y_test))\n",
    "\n",
    "dev = pd.DataFrame(devList, columns = ['id' , 'Gold Tag']) \n",
    "predicted= pd.DataFrame(predList, columns = ['id' , 'Gold Tag']) \n",
    "\n",
    "dev['Gold Tag'] = dev['Gold Tag'].astype('str')\n",
    "#dev = dev.astype(str)\n",
    "#dev = dev.replace(to_replace = \"\\.0+$\",value = \"\", regex = True)\n",
    "\n",
    "#predicted = predicted.astype(str)\n",
    "#predicted = predicted.replace(to_replace = \"\\.0+$\",value = \"\", regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.savetxt('dev.txt',dev,delimiter='\\t')\n",
    "#np.savetxt('predicted.txt',predicted,delimiter='\\t')\n",
    "\n",
    "np.savetxt(r'dev.txt', dev.values,fmt='%s')\n",
    "\n",
    "#dev.to_csv('dev.txt',sep=\"\\t\",index=False,dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _pickle as cPickle\n",
    "\n",
    "# save the classifier\n",
    "with open('nlp_classifier.pkl', 'wb') as fid:\n",
    "    cPickle.dump(classifier, fid)    \n",
    "\n",
    "# load it again\n",
    "with open('nlp_classifier.pkl', 'rb') as fid:\n",
    "    gnb_loaded = cPickle.load(fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = gnb_loaded.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.corpus import wordnet as wn\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from collections import defaultdict\n",
    "import pprint\n",
    "import argparse\n",
    "import difflib\n",
    "from googletrans import Translator\n",
    "import numpy as np\n",
    "import pickle\n",
    "translator = Translator()\n",
    "import time\n",
    "from nltk.corpus import wordnet_ic\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from nltk.corpus import wordnet as wn\n",
    "brown_ic = wordnet_ic.ic('ic-brown.dat')\n",
    "nltk.download('wordnet_ic')\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.corpus import wordnet as wn\n",
    "import gensim\n",
    "import os\n",
    "import collections\n",
    "import smart_open\n",
    "import re\n",
    "import random\n",
    "from collections import Counter\n",
    "import spotlight\n",
    "nltk.download('wordnet')\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "# Evaluation\n",
    "from sklearn.metrics import accuracy_score, precision_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "pd.set_option('display.max_columns', None)  \n",
    "\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "vec1 = KeyedVectors.load_word2vec_format(\"GoogleNews-vectors-negative300.bin\", binary=True)\n",
    "vec2 = KeyedVectors.load_word2vec_format(\"GoogleNews-vectors-negative300.bin\", binary=True)\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "\n",
    "#lemmatization\n",
    "def lemmatize(s):\n",
    "  \n",
    "    s = [lemmatizer.lemmatize(word) for word in s]\n",
    "    return s\n",
    "\n",
    "def dependency_parse(sentence):\n",
    "    doc=nlp(sentence)\n",
    "    for token in doc:    \n",
    "        if(token.dep_==\"ROOT\"):\n",
    "            return lemmatizer.lemmatize(token.text)\n",
    "        \n",
    "# =========== util func ==============\n",
    "def penn_to_wn(tag):\n",
    "    \"\"\" Convert between a Penn Treebank tag to a simplified Wordnet tag \"\"\"\n",
    "    if tag.startswith('N'): return 'n'\n",
    "    if tag.startswith('V'): return 'v'\n",
    "    if tag.startswith('J'): return 'a'\n",
    "    if tag.startswith('R'): return 'r'\n",
    "    return None\n",
    " \n",
    "def tagged_to_synset(word, tag):\n",
    "    wn_tag = penn_to_wn(tag)\n",
    "    if wn_tag is None:\n",
    "        return None\n",
    "    try:\n",
    "        return wn.synsets(word, wn_tag)[0]\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "notin_cnt = [0]\n",
    "# =========== feature extraction ==============\n",
    "def sentence_similarity_word_alignment(sentence1, sentence2):\n",
    "    \"\"\" compute the sentence similarity using Wordnet and ppdb \"\"\"\n",
    "    # Tokenize and tag\n",
    "    sentence1 = pos_tag(word_tokenize(sentence1))\n",
    "    sentence2 = pos_tag(word_tokenize(sentence2)) \n",
    "    # Get the synsets for the tagged words\n",
    "    synsets1 = [tagged_to_synset(*tagged_word) for tagged_word in sentence1]\n",
    "    synsets2 = [tagged_to_synset(*tagged_word) for tagged_word in sentence2]\n",
    "    # Filter out the Nones\n",
    "    synsets1 = [ss for ss in synsets1 if ss]\n",
    "    synsets2 = [ss for ss in synsets2 if ss]\n",
    "    score, count = 0.0, 0\n",
    "    ppdb_score, align_cnt = 0, 0\n",
    "    # For each word in the first sentence\n",
    "    for synset in synsets1:\n",
    "        # Get the similarity value of the most similar word in the other sentence\n",
    "        L = [synset.path_similarity(ss) for ss in synsets2]\n",
    "        L_prime = L\n",
    "        L = [l for l in L if l]\n",
    "\n",
    "      \n",
    "\n",
    "        if L: \n",
    "            best_score = max(L)\n",
    "            score += best_score\n",
    "            count += 1\n",
    "    # Average the values\n",
    "    if count >0: score /= count\n",
    "\n",
    "    return score\n",
    "\n",
    "def sentence_similarity_simple_baseline(s1, s2,counts = None):\n",
    "    def embedding_count(s):\n",
    "        ret_embedding = defaultdict(int)\n",
    "        for w in s.split():\n",
    "            w = w.strip('?.,')\n",
    "            ret_embedding[w] += 1\n",
    "        return ret_embedding\n",
    "    first_sent_embedding = embedding_count(s1)\n",
    "    second_sent_embedding = embedding_count(s2)\n",
    "    Embedding1 = []\n",
    "    Embedding2 = []\n",
    "    if counts:\n",
    "        for w in first_sent_embedding:\n",
    "            Embedding1.append(first_sent_embedding[w] * 1.0/ (counts[w]+0.001))\n",
    "            Embedding2.append(second_sent_embedding[w] *1.0/ (counts[w]+0.001))\n",
    "    else:\n",
    "        for w in first_sent_embedding:\n",
    "            Embedding1.append(first_sent_embedding[w])\n",
    "            Embedding2.append(second_sent_embedding[w])\n",
    "    ret_score = 0\n",
    "    if not 0 == sum(Embedding2): \n",
    "      \n",
    "        sm= difflib.SequenceMatcher(None,Embedding1,Embedding2)\n",
    "        ret_score = sm.ratio()*5 \n",
    "    return ret_score\n",
    "\n",
    "def extract_overlap_pen(s1, s2):\n",
    "    \"\"\"\n",
    "    :param s1:\n",
    "    :param s2:\n",
    "    :return: overlap_pen score\n",
    "    \"\"\"\n",
    "    ss1 = s1.strip().split()\n",
    "    ss2 = s2.strip().split()\n",
    "    ovlp_cnt = 0\n",
    "    for w1 in ss1:\n",
    "        ovlp_cnt += ss2.count(w1)\n",
    "    score = 2 * ovlp_cnt / (len(ss1) + len(ss2) + .0)\n",
    "    return score\n",
    "\n",
    "def all_token_diff(s1,s2):\n",
    "    s1, s2 = word_tokenize(s1), word_tokenize(s2)\n",
    "    pos1, pos2 = pos_tag(s1), pos_tag(s2)\n",
    "    # all tokens\n",
    "    return  abs(len(s1) - len(s2)) / float(len(s1) + len(s2))\n",
    "\n",
    "def adj_diff(s1,s2):\n",
    "    s1, s2 = word_tokenize(s1), word_tokenize(s2)\n",
    "    pos1, pos2 = pos_tag(s1), pos_tag(s2)\n",
    "    # all tokens\n",
    "    cnt1 = len([1 for item in pos1 if item[1].startswith('J')])\n",
    "    cnt2 = len([1 for item in pos2 if item[1].startswith('J')])\n",
    "    if cnt1 == 0 and cnt2 == 0:\n",
    "        t2 = 0\n",
    "    else:\n",
    "        t2 = abs(cnt1 - cnt2) / float(cnt1 + cnt2)\n",
    "        \n",
    "    return t2\n",
    "\n",
    "def adv_diff(s1,s2):\n",
    "    s1, s2 = word_tokenize(s1), word_tokenize(s2)\n",
    "    pos1, pos2 = pos_tag(s1), pos_tag(s2)\n",
    "    cnt1 = len([1 for item in pos1 if item[1].startswith('R')])\n",
    "    cnt2 = len([1 for item in pos2 if item[1].startswith('R')])\n",
    "    if cnt1 == 0 and cnt2 == 0:\n",
    "        t3 = 0\n",
    "    else:\n",
    "        t3 = abs(cnt1 - cnt2) / float(cnt1 + cnt2)\n",
    "        \n",
    "    return t3\n",
    "\n",
    "\n",
    "def noun_diff(s1,s2):\n",
    "    s1, s2 = word_tokenize(s1), word_tokenize(s2)\n",
    "    pos1, pos2 = pos_tag(s1), pos_tag(s2)\n",
    "    # all nouns\n",
    "    cnt1 = len([1 for item in pos1 if item[1].startswith('N')])\n",
    "    cnt2 = len([1 for item in pos2 if item[1].startswith('N')])\n",
    "    if cnt1 == 0 and cnt2 == 0:\n",
    "        t4 = 0\n",
    "    else:\n",
    "        t4 = abs(cnt1 - cnt2) / float(cnt1 + cnt2)\n",
    "        \n",
    "    return t4\n",
    "\n",
    "def verb_diff(s1,s2):\n",
    "    s1, s2 = word_tokenize(s1), word_tokenize(s2)\n",
    "    pos1, pos2 = pos_tag(s1), pos_tag(s2)\n",
    "    # all verbs\n",
    "    cnt1 = len([1 for item in pos1 if item[1].startswith('V')])\n",
    "    cnt2 = len([1 for item in pos2 if item[1].startswith('V')])\n",
    "    if cnt1 == 0 and cnt2 == 0:\n",
    "        t5 = 0\n",
    "    else:\n",
    "        t5 = abs(cnt1 - cnt2) / float(cnt1 + cnt2)\n",
    "    return t5\n",
    "\n",
    "def sentence_similarity_information_content(sentence1, sentence2):\n",
    "\n",
    "    ''' compute the sentence similairty using information content from wordnet '''\n",
    "    # Tokenize and tag\n",
    "    sentence1 = pos_tag(word_tokenize(sentence1))\n",
    "    sentence2 = pos_tag(word_tokenize(sentence2)) \n",
    "    # Get the synsets for the tagged words\n",
    "    synsets1 = [tagged_to_synset(*tagged_word) for tagged_word in sentence1]\n",
    "    synsets2 = [tagged_to_synset(*tagged_word) for tagged_word in sentence2]\n",
    "    # Filter out the Nones\n",
    "    synsets1 = [ss for ss in synsets1 if ss]\n",
    "    synsets2 = [ss for ss in synsets2 if ss]\n",
    "    score, count = 0.0, 0\n",
    "    ppdb_score, align_cnt = 0, 0\n",
    "    # For each word in the first sentence\n",
    "    for synset in synsets1:\n",
    "        L = []\n",
    "        for ss in synsets2:\n",
    "            try:\n",
    "                L.append(synset.res_similarity(ss, brown_ic))\n",
    "            except:\n",
    "                continue\n",
    "        if L: \n",
    "            best_score = max(L)\n",
    "            score += best_score\n",
    "            count += 1\n",
    "    # Average the values\n",
    "    if count >0: score /= count\n",
    "    return score\n",
    "\n",
    "\n",
    "def extract_res_vec_similarity(s1, s2):\n",
    "    first_sents_embeddings = np.empty([0,300])\n",
    "    second_sents_embeddings = np.empty([0,300])\n",
    "\n",
    "    first_vecs = np.array([])\n",
    "    for w in s1.split():\n",
    "        w = w.strip('?.,')\n",
    "        if w in vec1:\n",
    "            first_vec = np.array([vec1[w]])\n",
    "            if first_vecs.shape[0] == 0:\n",
    "                first_vecs = first_vec\n",
    "            else:\n",
    "                first_vecs = np.vstack((first_vecs, first_vec))\n",
    "        else:\n",
    "            if first_vecs.shape[0] == 0:\n",
    "                first_vecs = np.random.normal(0, 5, 300)\n",
    "            else:\n",
    "                first_vecs = np.vstack((first_vecs, np.random.normal(0, 5, 300)))\n",
    "        # print(\"first \")\n",
    "        # print(first_vecs.shape)\n",
    "    if(first_vecs.shape == (300, )):\n",
    "        temp = first_vecs\n",
    "    else:\n",
    "        temp = np.mean(first_vecs, axis=0)\n",
    "    # print(temp.shape)\n",
    "    first_sents_embeddings = np.append(first_sents_embeddings, [temp], axis=0)\n",
    "\n",
    "    second_vecs = np.array([])  \n",
    "    for w in s2.split():\n",
    "        w = w.strip('?.,')\n",
    "        if w in vec2:\n",
    "            second_vec = np.array([vec2[w]])\n",
    "            if second_vecs.shape[0] == 0:\n",
    "                second_vecs = second_vec\n",
    "            else:\n",
    "                second_vecs = np.vstack((second_vecs, second_vec))\n",
    "        else:\n",
    "            if second_vecs.shape[0] == 0:\n",
    "                second_vecs = np.random.normal(0, 5, 300)\n",
    "            else:\n",
    "                second_vecs = np.vstack((second_vecs, np.random.normal(0, 5, 300)))\n",
    "        # print(\"second \")\n",
    "        # print(second_vecs.shape)\n",
    "    if(second_vecs.shape == (300,)):\n",
    "        temp = second_vecs\n",
    "    else:\n",
    "        temp = np.mean(second_vecs, axis=0)\n",
    "    # print(temp.shape)\n",
    "    second_sents_embeddings = np.append(second_sents_embeddings, [temp], axis=0)\n",
    "\n",
    "    for i in range(len(first_sents_embeddings)):\n",
    "        # cosine similarity\n",
    "\n",
    "        ret = np.dot(first_sents_embeddings[i], second_sents_embeddings[i]) / (np.linalg.norm(first_sents_embeddings[i]) * np.linalg.norm(second_sents_embeddings[i]))\n",
    "        ret = 5*(ret + 1) / 2\n",
    "\n",
    "    return ret\n",
    "\n",
    "\n",
    "def extract_doc2vec_similarity(s1,s2, model):\n",
    "    s1 = [w.strip('?.,') for w in s1.split()]\n",
    "    s2 = [w.strip('?.,') for w in s2.split()]\n",
    "    embed1 = model.infer_vector(s1)\n",
    "    embed2 = model.infer_vector(s2)\n",
    "    ret = np.dot(embed1,embed2)\n",
    "    return ret\n",
    "\n",
    "\n",
    "\n",
    "def duplicates(value1,value2):\n",
    "    \n",
    "    dups = Counter(value1) - Counter(value2)\n",
    "    return len(dups)\n",
    "\n",
    "def get_annotation(text):\n",
    "   # print(text)\n",
    "    try:\n",
    "        annotations = spotlight.annotate('http://api.dbpedia-spotlight.org/en/annotate',text,\n",
    "                              confidence=0.4, support=20)\n",
    "    except Exception as e:\n",
    "       # print(e)\n",
    "        return {'URI':[],'types':[]}\n",
    "    \n",
    "    URI_lst=[]\n",
    "    types_lst=[]\n",
    "    \n",
    "    for ann_dict in annotations:\n",
    "        URI_lst.append(ann_dict['URI'])\n",
    "        types_lst.append(ann_dict['types'])\n",
    "    \n",
    "    return {'URI':URI_lst,'types':types_lst}\n",
    "\n",
    "def get_common_types(sent1_types,sent2_types):\n",
    "    s1=set(sent1_types)\n",
    "    s2=set(sent2_types)\n",
    "    if len(s1.union(s2))>0:\n",
    "        return len(s1.intersection(s2))/len(s1.union(s2))\n",
    "    return 0.5\n",
    "\n",
    "\n",
    "\n",
    "def get_common_entities(text1,text2):\n",
    "    doc1 = nlp(text1)\n",
    "    doc2 = nlp(text2)\n",
    "    ent1={X.label_  for X in doc1.ents}\n",
    "    ent2={X.label_  for X in doc2.ents}\n",
    "    if len(ent1.union(ent2))>0:\n",
    "        return len(ent1.intersection(ent2))/len(ent1.union(ent2))\n",
    "    return 0.5\n",
    "\n",
    "#classes to return text and numeric values for transformer\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class TextSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, field):\n",
    "        self.field = field\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.field]\n",
    "class NumberSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, field):\n",
    "        self.field = field\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[[self.field]]\n",
    "    \n",
    "    \n",
    "def Tokenizer(str_input):\n",
    "    words = re.sub(r\"[^A-Za-z0-9\\-]\", \" \", str_input).lower().split()\n",
    "    return lemmatize(words)\n",
    "\n",
    "def build_features(train):\n",
    "    \n",
    "    Counts_for_tf = defaultdict(int)\n",
    "    \n",
    "    for sent in train['Sentence1'].tolist():\n",
    "        for w in [w.strip(\"?.,\") for w in sent.split()]: Counts_for_tf[w] += 1\n",
    "    for sent in train['Sentence2'].tolist():\n",
    "        for w in [w.strip(\"?.,\") for w in sent.split()]: Counts_for_tf[w] += 1\n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "    #tokenization    \n",
    "    train['tokenized_sent1'] = train.apply(lambda row: nltk.word_tokenize(row['Sentence1']), axis=1)\n",
    "    train['tokenized_sent2'] = train.apply(lambda row: nltk.word_tokenize(row['Sentence2']), axis=1)\n",
    "    \n",
    "    #lemmatization\n",
    "    train['lemmatized_sent1'] = train.apply(lambda row: lemmatize(row['tokenized_sent1']), axis=1)\n",
    "    train['lemmatized_sent2'] = train.apply(lambda row: lemmatize(row['tokenized_sent2']), axis=1)\n",
    "    \n",
    "    #stop words removal    \n",
    "    train['lemmatized_sent1'].apply(lambda x: [item for item in x if item not in stop])\n",
    "    train['lemmatized_sent2'].apply(lambda x: [item for item in x if item not in stop])\n",
    "\n",
    "    #POS tags    \n",
    "    train['POS_Tags1'] = train.apply(lambda row: nltk.pos_tag(row['lemmatized_sent1']), axis=1)\n",
    "    train['POS_Tags2'] = train.apply(lambda row: nltk.pos_tag(row['lemmatized_sent2']), axis=1)\n",
    "    \n",
    "    train['Root1'] = train.apply(lambda row: dependency_parse(row['Sentence1']), axis=1)\n",
    "    train['Root2'] = train.apply(lambda row: dependency_parse(row['Sentence2']), axis=1)\n",
    "    \n",
    "    train['flagCheckRoot'] = train.apply(lambda row: row['Root1']==row['Root2'], axis=1)\n",
    "    \n",
    "    train['baseline_sim']=train.apply(lambda row: sentence_similarity_simple_baseline(row['Sentence1'],row['Sentence2'],Counts_for_tf), axis=1)\n",
    "    train['word_align_sim']=train.apply(lambda row: sentence_similarity_word_alignment(row['Sentence1'],row['Sentence2']), axis=1)\n",
    "    \n",
    "    train['baseline_sim']=train.apply(lambda row: sentence_similarity_simple_baseline(row['Sentence1'],row['Sentence2'],Counts_for_tf), axis=1)\n",
    "    train['word_align_sim']=train.apply(lambda row: sentence_similarity_word_alignment(row['Sentence1'],row['Sentence2']), axis=1)\n",
    "    train['info_con_sim']=train.apply(lambda row: sentence_similarity_information_content(row['Sentence1'],row['Sentence2']), axis=1)\n",
    "    train['tag_overlap']=train.apply(lambda row: extract_overlap_pen(row['Sentence1'],row['Sentence2']), axis=1)\n",
    "    \n",
    "    train['verb_diff']=train.apply(lambda row: verb_diff(row['Sentence1'],row['Sentence2']), axis=1)\n",
    "    train['noun_diff']=train.apply(lambda row: noun_diff(row['Sentence1'],row['Sentence2']), axis=1)\n",
    "    train['adj_diff']=train.apply(lambda row: adj_diff(row['Sentence1'],row['Sentence2']), axis=1)\n",
    "    train['adv_diff']=train.apply(lambda row: adv_diff(row['Sentence1'],row['Sentence2']), axis=1)\n",
    "    \n",
    "    \n",
    "    train['mmr']=train.apply(lambda row: extract_mmr_t(row['Sentence1'],row['Sentence2']), axis=1)\n",
    "    train['res_sim']=train.apply(lambda row: extract_res_vec_similarity(row['Sentence1'],row['Sentence2']), axis=1)\n",
    "    \n",
    "    train['no_ques_diff']=train.apply(lambda row: (row['Sentence1'].count(\"?\")-row['Sentence2'].count(\"?\")), axis=1)\n",
    "    train['no_excl_diff']=train.apply(lambda row: (row['Sentence1'].count(\"!\")-row['Sentence2'].count(\"!\")), axis=1)\n",
    "    \n",
    "    \n",
    "    train['annotations_s1'] = train.apply(lambda row: get_annotation(row['Sentence1']), axis=1)\n",
    "    train['annotations_s2'] = train.apply(lambda row: get_annotation(row['Sentence2']), axis=1)\n",
    "    \n",
    "    \n",
    "    # NER features\n",
    "\n",
    "    train['num_same_URI'] = train.apply(lambda row: duplicates(row['annotations_s1']['URI'],row['annotations_s2']['URI']), axis=1)\n",
    "    # NER features\n",
    "\n",
    "    train['overlap_types'] = train.apply(lambda row:get_common_types(row['annotations_s1']['types'],row['annotations_s2']['types']), axis=1)\n",
    "    \n",
    "    train['common_entities'] = train.apply(lambda row: get_common_entities(row['Sentence1'],row['Sentence2']), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #train_file=sys.argv[0]\n",
    "    train_file='data/train-set.txt'\n",
    "    train = pd.read_csv(train_file, sep=\"\\t\",error_bad_lines=False)\n",
    "    train = train[np.isfinite(train['Gold Tag'])]  #remove nan values\n",
    "    \n",
    "    processed_train=build_features(train)\n",
    "    \n",
    "    X=processed_train[[ 'baseline_sim','Sentence1','Sentence2',\n",
    "       'word_align_sim', 'tag_overlap', 'res_sim', 'no_ques_diff', 'no_excl_diff', 'num_same_URI', 'overlap_types','common_entities', 'verb_diff', 'noun_diff', 'adj_diff', 'adv_diff']]\n",
    "    Y = processed_train.loc[:, 'Gold Tag']\n",
    "    \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25)\n",
    "    \n",
    "    all_corpus=train['Sentence1'].tolist()+train['Sentence2'].tolist()\n",
    "    \n",
    "    classifier = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "        ('tfidf1', Pipeline([\n",
    "            ('colext', TextSelector('Sentence1')),\n",
    "            ('tfidf', TfidfVectorizer(tokenizer=Tokenizer, stop_words=stop_words,\n",
    "                     min_df=.0025, max_df=0.25, ngram_range=(1,2))),\n",
    "            ('svd', TruncatedSVD(algorithm='randomized', n_components=300)), \n",
    "        ])),\n",
    "       ('tfidf2', Pipeline([\n",
    "            ('colext', TextSelector('Sentence2')),\n",
    "            ('tfidf', TfidfVectorizer(tokenizer=Tokenizer, stop_words=stop_words,\n",
    "                     min_df=.0025, max_df=0.25, ngram_range=(1,2))),\n",
    "            ('svd', TruncatedSVD(algorithm='randomized', n_components=300)), \n",
    "        ])),\n",
    "        ('no_ques_diff', Pipeline([\n",
    "            ('wordext', NumberSelector('no_ques_diff')),\n",
    "            ('wscaler', StandardScaler()),\n",
    "        ])),\n",
    "         ('no_excl_diff', Pipeline([\n",
    "            ('wordext', NumberSelector('no_excl_diff')),\n",
    "            ('wscaler', StandardScaler()),\n",
    "        ])),\n",
    "         ('baseline_sim', Pipeline([\n",
    "            ('wordext', NumberSelector('baseline_sim')),\n",
    "            ('wscaler', StandardScaler()),\n",
    "        ])),\n",
    "         ('word_align_sim', Pipeline([\n",
    "            ('wordext', NumberSelector('word_align_sim')),\n",
    "            ('wscaler', StandardScaler()),\n",
    "        ])),\n",
    "         ('res_sim', Pipeline([\n",
    "            ('wordext', NumberSelector('res_sim')),\n",
    "            ('wscaler', StandardScaler()),\n",
    "        ])),\n",
    "         ('num_same_URI', Pipeline([\n",
    "            ('wordext', NumberSelector('num_same_URI')),\n",
    "            ('wscaler', StandardScaler()),\n",
    "        ])),\n",
    "         ('info_con_sim', Pipeline([\n",
    "            ('wordext', NumberSelector('info_con_sim')),\n",
    "        \n",
    "        ])),\n",
    "           ('common_entities', Pipeline([\n",
    "            ('wordext', NumberSelector('common_entities')),\n",
    "        \n",
    "        ])),\n",
    "           ('verb_diff', Pipeline([\n",
    "            ('wordext', NumberSelector('verb_diff')),\n",
    "        \n",
    "        ])),\n",
    "         ('noun_diff', Pipeline([\n",
    "            ('wordext', NumberSelector('noun_diff')),\n",
    "        \n",
    "        ])),\n",
    "        ('adj_diff', Pipeline([\n",
    "            ('wordext', NumberSelector('adj_diff')),\n",
    "        \n",
    "        ])),\n",
    "        ('adv_diff', Pipeline([\n",
    "            ('wordext', NumberSelector('adv_diff')),\n",
    "        \n",
    "        ])),\n",
    "         ('overlap_types', Pipeline([\n",
    "            ('wordext', NumberSelector('overlap_types')),\n",
    "           \n",
    "        ])),\n",
    "           ('tag_overlap', Pipeline([\n",
    "            ('wordext', NumberSelector('tag_overlap')),\n",
    "           \n",
    "        ]))\n",
    "    ])),\n",
    "#    ('clf', XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.1)),\n",
    "   ('rf', RandomForestClassifier()),\n",
    "  #('svr',SVR(kernel='linear')),\n",
    "     ])\n",
    "            \n",
    "\n",
    "    \n",
    "    classifier.fit(X_train, y_train) \n",
    "    # save the classifier\n",
    "with open('nlp_classifier.pkl', 'wb') as fid:\n",
    "    cPickle.dump(classifier, fid)    \n",
    "\n",
    "    preds = classifier.predict(X_test)\n",
    "    \n",
    "    return y_test,preds\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
